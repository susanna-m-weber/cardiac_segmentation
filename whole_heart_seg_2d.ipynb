{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8d2j10l1UKsu"
   },
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "from nibabel import processing\n",
    "\n",
    "from skimage import io\n",
    "from skimage.transform import resize\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import warnings\n",
    "import shutil\n",
    "\n",
    "import SimpleITK as sitk\n",
    "# from nipype.interfaces.ants import N4BiasFieldCorrection\n",
    "from scipy import misc\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "import albumentations as A\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4OskS-VhXIVq",
    "outputId": "285ae152-5637-4c4b-ec8d-5160bf6c0acb"
   },
   "outputs": [],
   "source": [
    "# grab all of the images and stack them. Do the same with the masks\n",
    "data_root_folder = Path('C:/Users/Susanna/Documents/Heart_Segmentation/data/')\n",
    "scans_dir = Path('C:/Users/Susanna/Documents/Heart_Segmentation/lung/')\n",
    "masks_dir = Path('C:/Users/Susanna/Documents/Heart_Segmentation/masks/')\n",
    "\n",
    "# grab all the images in the directories\n",
    "scans_nifti = sorted(scans_dir.glob('*.nii'))\n",
    "masks_nifti = sorted(masks_dir.glob('*.nii'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fJStMIGdcEhW"
   },
   "outputs": [],
   "source": [
    "# get information from each nifti file\n",
    "def load_scan(scans_nifti):\n",
    "  result_data = []\n",
    "  result_img_format = []\n",
    "  paths = []\n",
    "  for scan in scans_nifti:\n",
    "    loaded_scan = nib.load(scan)\n",
    "    data = loaded_scan.get_fdata()\n",
    "    result_data.append(np.squeeze(data))\n",
    "    result_img_format.append(processing.conform(nib.Nifti1Image(np.squeeze(data), loaded_scan.affine), out_shape=data.shape))\n",
    "    paths.append(scan)\n",
    "  return result_data, result_img_format, paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D7krrNQqbVpM"
   },
   "outputs": [],
   "source": [
    "output_scans, scan_imgs, scan_list = load_scan(scans_nifti) # [load_scan(scan) for scan in scans_nifti]\n",
    "output_masks, mask_imgs, mask_list = load_scan(masks_nifti) # [load_scan(mask) for mask in masks_nifti]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ohd5g836dUCc",
    "outputId": "54b70ee4-6ae6-4412-948c-e07379960ecb"
   },
   "outputs": [],
   "source": [
    "# helper functions for working with data \n",
    "\n",
    "def is_binary_data(file_path):\n",
    "    # Load the MRI volume using nibabel\n",
    "    img = nib.load(file_path)\n",
    "\n",
    "    # Get the data array from the image\n",
    "    data = img.get_fdata()\n",
    "\n",
    "    # Check if the data is binary\n",
    "    unique_values = np.unique(data)\n",
    "    is_binary = len(unique_values) == 2\n",
    "\n",
    "    return is_binary\n",
    "\n",
    "def find_max_voxel_value(file_path):\n",
    "    # Load the MRI volume using nibabel\n",
    "    img = nib.load(file_path)\n",
    "\n",
    "    # Get the data array from the image\n",
    "    data = img.get_fdata()\n",
    "\n",
    "    # Find the maximum voxel value\n",
    "    max_voxel_value = np.max(data)\n",
    "    min_voxel_value = np.min(data)\n",
    "\n",
    "    return max_voxel_value, min_voxel_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2WWKcuRKeCtb"
   },
   "outputs": [],
   "source": [
    "scan_slices_dir = Path('C:/Users/Susanna/Documents/Heart_Segmentation/old/scan_slices/')\n",
    "mask_slices_dir = Path('C:/Users/Susanna/Documents/Heart_Segmentation/old/scan_slices/mask_slices/')\n",
    "\n",
    "scan_slices_train_dir = Path('C:/Users/Susanna/Documents/Heart_Segmentation/data/train/scan/')\n",
    "mask_slices_train_dir = Path('C:/Users/Susanna/Documents/Heart_Segmentation/data/train/mask/')\n",
    "\n",
    "scan_slices_valid_dir = Path('C:/Users/Susanna/Documents/Heart_Segmentation/data/valid/scan/')\n",
    "mask_slices_valid_dir = Path('C:/Users/Susanna/Documents/Heart_Segmentation/data/valid/mask/')\n",
    "\n",
    "scan_slices_test_dir = Path('C:/Users/Susanna/Documents/Heart_Segmentation/data/test/scan/')\n",
    "mask_slices_test_dir = Path('C:/Users/Susanna/Documents/Heart_Segmentation/data/test/mask/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1HESAmwm8XWd",
    "outputId": "6f8c3ac2-678a-4bd5-caa1-bd24454336d0"
   },
   "outputs": [],
   "source": [
    "# sanity check for number of images and masks in each folder \n",
    "num_train_masks = mask_slices_train_dir.glob('*.nii.gz')\n",
    "num_train_masks = list(num_train_masks)\n",
    "print(len(num_train_masks))\n",
    "num_valid_masks = mask_slices_valid_dir.glob('*.nii.gz')\n",
    "num_valid_masks = list(num_valid_masks)\n",
    "print(len(num_valid_masks))\n",
    "num_test_masks = mask_slices_test_dir.glob('*.nii.gz')\n",
    "num_test_masks = list(num_test_masks)\n",
    "print(len(num_test_masks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qiqX69vxE9ur"
   },
   "outputs": [],
   "source": [
    "# the data here are stored as 2D slices, but I want to be able to reconstruct them into 3D scans, and also reconstruct the masks into 3D objects.\n",
    "# So, I want a way to retrive not just the scan number in the folder the 2D slice it is in, but also its position in the stack of slices that make up the scan \n",
    "\n",
    "def get_ind(path):\n",
    "  slice_num = int(re.findall(r'\\d+', path)[0])\n",
    "  if 'valid' in path:\n",
    "    start = 56\n",
    "  elif 'test' in path:\n",
    "    start = 72\n",
    "  else:\n",
    "    start = 1\n",
    "  if slice_num <= 36:\n",
    "    slice_in_scan = slice_num\n",
    "    scan_num = start\n",
    "  if slice_num > 36:\n",
    "    scan_num = int(slice_num/36)\n",
    "    slice_in_scan = slice_num - (scan_num * 36) - start + 1\n",
    "  return slice_in_scan, scan_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q4c_mgLUBl12"
   },
   "outputs": [],
   "source": [
    "# creating the dataset \n",
    "class BasicDataset(TensorDataset):\n",
    "    def __init__(self, folder, n_sample=None, transform=None):\n",
    "        self.folder = os.path.join(data_root_folder, folder)\n",
    "        self.imgs_dir = os.path.join(self.folder, 'scan')\n",
    "        self.masks_dir = os.path.join(self.folder, 'mask')\n",
    "\n",
    "        self.imgs_file = sorted(glob.glob(os.path.join(self.imgs_dir, '*.nii.gz')))\n",
    "        self.masks_file = sorted(glob.glob(os.path.join(self.masks_dir, '*.nii.gz')))\n",
    "\n",
    "        assert len(self.imgs_file) == len(self.masks_file), 'There are some missing images or masks in {0}'.format(folder)\n",
    "\n",
    "        if not n_sample or n_sample > len(self.imgs_file):\n",
    "            n_sample = len(self.imgs_file)\n",
    "\n",
    "        self.n_sample = n_sample\n",
    "        self.ids = list([i+1 for i in range(n_sample)])\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_sample\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        idx = self.ids[i]\n",
    "        scan_path = os.path.join(self.imgs_dir, f\"scan_{str(i+1)}.nii.gz\")\n",
    "        mask_path = os.path.join(self.imgs_dir, f\"mask_{str(i+1)}.nii.gz\")\n",
    "\n",
    "\n",
    "        slice_in_scan  = get_ind(scan_path)[0]\n",
    "        scan_num = get_ind(scan_path)[1]\n",
    "\n",
    "        img = nib.load(os.path.join(self.imgs_dir, f\"scan_{str(i+1)}.nii.gz\")).get_fdata()\n",
    "        mask = nib.load(os.path.join(self.masks_dir, f\"mask_{str(i+1)}.nii.gz\")).get_fdata()\n",
    "\n",
    "        # Scale between 0 to 1\n",
    "        scan_max = np.max(img)\n",
    "        img = np.array(img) / scan_max\n",
    "\n",
    "         # data augmentation\n",
    "        if self.transform is not None:\n",
    "            augmented = self.transform(image=img, mask=mask)\n",
    "            img = augmented[\"image\"]\n",
    "            mask = augmented[\"mask\"]\n",
    "\n",
    "        # Add an axis to the mask array so that it is in [channel, width, height] format.\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        mask = np.expand_dims(mask, axis=0)\n",
    "\n",
    "        # return the slice position in the 36 slices making up the scan, as well as scan, mask, and ID\n",
    "        return {\n",
    "            'scan': torch.from_numpy(img).type(torch.FloatTensor),\n",
    "            'mask': torch.from_numpy(mask).type(torch.FloatTensor),\n",
    "            'img_id': idx,\n",
    "            'slice_in_scan': slice_in_scan,\n",
    "            'scan_num': scan_num,\n",
    "            'max_pixel': scan_max\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image augmentation \n",
    "transforms = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "], is_check_shapes=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 699
    },
    "id": "Jjc9Jvg9HGA-",
    "outputId": "c93e8b96-4ad5-4ae6-c60e-314e7e64595c"
   },
   "outputs": [],
   "source": [
    "# Create train, validation, and test dataset instances\n",
    "train_dataset = BasicDataset('train', transform=transforms)\n",
    "valid_dataset = BasicDataset('valid', transform=transforms)\n",
    "test_dataset = BasicDataset('test', transform=transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 636
    },
    "id": "AjS3iGRnK6Jq",
    "outputId": "d002a624-fd3d-4dd0-cb8a-95f2b2fef112"
   },
   "outputs": [],
   "source": [
    "# have a look at data \n",
    "plt.figure(figsize=(12, 8), dpi=100)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Image')\n",
    "plt.imshow((output_scans[10][:,:,1]), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('Mask')\n",
    "plt.imshow(output_masks[10][:,:,1], cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xARWTPQwnWhh"
   },
   "outputs": [],
   "source": [
    "# recombine 2D slices into 3D scans - helper function for putting together 3D masks after training\n",
    "def recombine_slices(num_imgs, dataset_type, output_path):\n",
    "  start_slice = 0\n",
    "  end_slice = 36\n",
    "  for i in range(num_imgs): # loop that goes through 3D imgs\n",
    "    scan_nifti = scan_imgs[i]\n",
    "    mask_nifti = mask_imgs[i]\n",
    "\n",
    "    curr_img = np.empty((64,64))\n",
    "    curr_mask = np.empty((64,64))\n",
    "\n",
    "    print(f\"The start slice is {start_slice}\")\n",
    "    print(f\"The end slice is {end_slice}\")\n",
    "\n",
    "    for j in range(start_slice, end_slice): # loop that goes through slices\n",
    "      data = dataset_type.__getitem__(j)\n",
    "      scan_slice = data['scan']\n",
    "      mask_slice = data['mask']\n",
    "\n",
    "      scan_slice = np.squeeze(scan_slice)\n",
    "      mask_slice = np.squeeze(mask_slice)\n",
    "\n",
    "      scan_slice = scan_slice.numpy()\n",
    "      mask_slice = mask_slice.numpy()\n",
    "\n",
    "      curr_img = np.dstack([curr_img, scan_slice[ :, :, None]])\n",
    "      curr_mask = np.dstack([curr_mask, mask_slice[ :, :, None]])\n",
    "\n",
    "      curr_img = np.squeeze(curr_img)\n",
    "      curr_mask = np.squeeze(curr_mask)\n",
    "\n",
    "    curr_img = curr_img[:,:,1:curr_img.shape[2]]\n",
    "    curr_mask = curr_mask[:,:,1:curr_mask.shape[2]]\n",
    "\n",
    "    print(f\"Current image shape {curr_img.shape}\")\n",
    "    print(f\"Current mask shape {curr_mask.shape}\")\n",
    "\n",
    "    curr_img_nifti = processing.conform(nib.Nifti1Image(curr_img, scan_nifti.affine), out_shape=curr_img.shape) # save curr_img as a nifti at output path\n",
    "    curr_mask_nifti = processing.conform(nib.Nifti1Image(curr_mask, mask_nifti.affine), out_shape=curr_mask.shape)# save curr mask as a nifti at output path\n",
    "\n",
    "    img_nifti_path = 'C:/Users/Susanna/Documents/Heart_Segmentation/output/scan_'  + str(i + 1) + '.nii.gz'\n",
    "    mask_nifti_path = 'C:/Users/Susanna/Documents/Heart_Segmentation/output/mask'+  + str(i + 1) + '.nii.gz'\n",
    "    # TO DO: Update this for non-colab version\n",
    "    nib.save(curr_img_nifti, Path(img_nifti_path))\n",
    "    nib.save(curr_mask_nifti, Path(mask_nifti_path))\n",
    "\n",
    "    start_slice += 36\n",
    "    end_slice += 36\n",
    "\n",
    "    print(\"outer loop done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2gH8dxvyX_K5"
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=0, pin_memory=True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=2, num_workers=0, pin_memory=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=2, num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IYjZy6fqPc94"
   },
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.up_conv = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1, padding=0),\n",
    "        )\n",
    "        self.conv = DoubleConv(out_channels * 2, out_channels)\n",
    "\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up_conv(x1)\n",
    "        x = torch.cat([x1, x2], dim=1)\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv_sigmoid = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv_sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XZnNGsxM3JaZ"
   },
   "outputs": [],
   "source": [
    "# define model - standard unet architecture \n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, name, n_channels, n_classes):\n",
    "        super(UNet, self).__init__()\n",
    "        self.name = name\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "        self.inputL = DoubleConv(n_channels, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.down3 = Down(256, 512)\n",
    "        self.down4 = Down(512, 1024)\n",
    "        self.up1 = Up(1024, 512)\n",
    "        self.up2 = Up(512, 256)\n",
    "        self.up3 = Up(256, 128)\n",
    "        self.up4 = Up(128, 64)\n",
    "        self.outputL = OutConv(64, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.inputL(x)\n",
    "\n",
    "        x1 = self.down1(x0)\n",
    "        x2 = self.down2(x1)\n",
    "        x3 = self.down3(x2)\n",
    "        x4 = self.down4(x3)\n",
    "\n",
    "        x = self.up1(x4, x3)\n",
    "        x = self.up2(x, x2)\n",
    "        x = self.up3(x, x1)\n",
    "        x = self.up4(x, x0)\n",
    "\n",
    "        x = self.outputL(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "11p0mdwA3O9T",
    "outputId": "50f34b94-09b5-4e2d-eb9c-76968041e43c"
   },
   "outputs": [],
   "source": [
    "my_UNet = UNet('MyUNet', n_channels=1, n_classes=1)\n",
    "my_UNet.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rwcA4lQqf_WV"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(my_UNet.parameters(), lr=0.001)\n",
    "loss_function = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dMTG6oE8gZZw"
   },
   "outputs": [],
   "source": [
    "def dice_coeff_binary(y_pred, y_true):\n",
    "        eps = 0.0001\n",
    "        inter = torch.dot(y_pred.view(-1), y_true.view(-1))\n",
    "        union = torch.sum(y_pred) + torch.sum(y_true)\n",
    "        return ((2 * inter.float() + eps) / (union.float() + eps)).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2PMdBvSDggqv"
   },
   "outputs": [],
   "source": [
    "def train_net(net, epochs, train_dataloader, valid_dataloader, optimizer, loss_function):\n",
    "\n",
    "    if not os.path.isdir('{0}'.format(net.name)):\n",
    "        os.mkdir('{0}'.format(net.name))\n",
    "\n",
    "    n_train = len(train_dataloader)\n",
    "    n_valid = len(valid_dataloader)\n",
    "\n",
    "    train_loss = list()\n",
    "    valid_loss = list()\n",
    "    train_dice = list()\n",
    "    valid_dice = list()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # training loop\n",
    "        net.train()\n",
    "        train_batch_loss = list()\n",
    "        train_batch_dice = list()\n",
    "\n",
    "        for i, batch in enumerate(train_dataloader):\n",
    "\n",
    "            # Load a batch and pass it to the GPU\n",
    "            imgs = batch['scan'].cuda()\n",
    "            true_masks = batch['mask'].cuda()\n",
    "\n",
    "            # Produce the estimated mask using current weights\n",
    "            y_pred = net(imgs)\n",
    "\n",
    "            # Compute the loss for this batch and append it to the epoch loss\n",
    "            loss = loss_function(y_pred, true_masks)\n",
    "            batch_loss = loss.item()\n",
    "            train_batch_loss.append(batch_loss)\n",
    "\n",
    "            # Make the thresholded mask to compute the DICE score\n",
    "            pred_binary = (y_pred > 0.5).float()                    \n",
    "\n",
    "            # Compute the DICE score \n",
    "            batch_dice_score = dice_coeff_binary(pred_binary, true_masks)\n",
    "            train_batch_dice.append(batch_dice_score)\n",
    "\n",
    "\n",
    "            # Reset gradient \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Compute losses\n",
    "            loss.backward()\n",
    "\n",
    "            # Update the weights\n",
    "            optimizer.step()\n",
    "\n",
    "            # Print the progress\n",
    "            print(f'EPOCH {epoch + 1}/{epochs} - Training Batch {i+1}/{n_train} - Loss: {batch_loss}, DICE score: {batch_dice_score}', end='\\r')\n",
    "\n",
    "        average_training_loss = np.array(train_batch_loss).mean()\n",
    "        average_training_dice = np.array(train_batch_dice).mean()\n",
    "        train_loss.append(average_training_loss)\n",
    "        train_dice.append(average_training_dice)\n",
    "\n",
    "        # validation loop\n",
    "\n",
    "        net.eval()\n",
    "        valid_batch_loss = list()\n",
    "        valid_batch_dice = list()\n",
    "\n",
    "     \n",
    "        with torch.no_grad():\n",
    "            for i, batch in enumerate(valid_dataloader):\n",
    "\n",
    "                imgs = batch['scan'].cuda()\n",
    "                true_masks = batch['mask'].cuda()\n",
    "\n",
    "                y_pred = net(imgs)\n",
    "\n",
    "                # Compute the loss for this batch and append it to the epoch loss\n",
    "                loss = loss_function(y_pred, true_masks)\n",
    "                batch_loss = loss.item()\n",
    "                valid_batch_loss.append(batch_loss)\n",
    "\n",
    "                # Make the thresholded mask to compute the DICE score\n",
    "                pred_binary = (y_pred > 0.5).float()                  \n",
    "\n",
    "                # Compute the DICE score\n",
    "                batch_dice_score = dice_coeff_binary(pred_binary, true_masks)\n",
    "                valid_batch_dice.append(batch_dice_score)\n",
    "\n",
    "                print(f'EPOCH {epoch + 1}/{epochs} - Validation Batch {i+1}/{n_valid} - Loss: {batch_loss}, DICE score: {batch_dice_score}', end='\\r')\n",
    "\n",
    "        average_validation_loss = np.array(valid_batch_loss).mean()\n",
    "        average_validation_dice = np.array(valid_batch_dice).mean()\n",
    "        valid_loss.append(average_validation_loss)\n",
    "        valid_dice.append(average_validation_dice)\n",
    "\n",
    "        print(f'EPOCH {epoch + 1}/{epochs} - Training Loss: {average_training_loss}, Training DICE score: {average_training_dice}, Validation Loss: {average_validation_loss}, Validation DICE score: {average_validation_dice}')\n",
    "\n",
    "\n",
    "    return train_loss, train_dice, valid_loss, valid_dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p9AuCrX3b_--",
    "outputId": "511af9e1-0453-40b3-81c6-82b27a56eb76"
   },
   "outputs": [],
   "source": [
    "model_path = Path('C:/Users/Susanna/Documents/Heart_Segmentation/2d_unet.pth')\n",
    "EPOCHS = 30\n",
    "train_loss, train_dice, valid_loss, valid_dice = train_net(my_UNet, EPOCHS, train_dataloader, valid_dataloader, optimizer, loss_function)\n",
    "torch.save(my_UNet.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 806
    },
    "id": "qJRD0CuzxUc1",
    "outputId": "f6337bf0-c1aa-4b53-af28-fe8e3dd3450d"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "plt.suptitle('Learning Curve', fontsize=18)\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(np.arange(EPOCHS)+1, train_loss, '-o', label='Training Loss')\n",
    "plt.plot(np.arange(EPOCHS)+1, valid_loss, '-o', label='Validation Loss')\n",
    "# plt.xticks(np.arange(EPOCHS)+1)\n",
    "plt.xlabel('Epoch', fontsize=15)\n",
    "plt.ylabel('Loss', fontsize=15)\n",
    "plt.yticks(np.arange(0, 0.1, 0.02))\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(np.arange(EPOCHS)+1, train_dice, '-o', label='Training DICE score')\n",
    "plt.plot(np.arange(EPOCHS)+1, valid_dice, '-o', label='Validation DICE score')\n",
    "# plt.xticks(np.arange(EPOCHS)+1)\n",
    "plt.yticks(np.arange(0.6, 1, 0.05))\n",
    "plt.xlabel('Epoch', fontsize=15)\n",
    "plt.ylabel('DICE score', fontsize=15)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(my_UNet.state_dict(), 'model_weights_2d_UNet.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the first batch\n",
    "batches = []\n",
    "test_num = 0\n",
    "\n",
    "for batch in test_dataloader:\n",
    "    sample_batch = batch\n",
    "    batches.append(batch)\n",
    "\n",
    "sample_batch = batches[0] \n",
    "\n",
    "# Generate network prediction\n",
    "with torch.no_grad():\n",
    "    y_pred = my_UNet(sample_batch['scan'].cuda())\n",
    "\n",
    "\n",
    "test_num = 1 #0 #1\n",
    "# Conver Pytorch tensor to numpy array then reverse the preprocessing steps\n",
    "img = (sample_batch['scan'][test_num].numpy().transpose(1,2,0) * 255).astype('uint8')\n",
    "msk = (sample_batch['mask'][test_num][0,:,:].numpy() * 255).astype('uint8')\n",
    "\n",
    "# Exctract the relative prediction mask and threshold the probablities (>0.5)\n",
    "pred_msk = (y_pred.cpu().numpy()[test_num][0,:,:] * 255).astype('uint8')\n",
    "pred_msk_binary = ((y_pred.cpu().numpy()[test_num][0,:,:] > 0.5) * 255).astype('uint8')\n",
    "\n",
    "# Take the image id for display\n",
    "img_id = sample_batch['img_id'][0]\n",
    "\n",
    "plt.figure(figsize=(24,9))\n",
    "plt.suptitle(f'Test sample Image {img_id}', fontsize=18)\n",
    "\n",
    "plt.subplot(1,4,1)\n",
    "plt.title('Input Image', fontsize=15)\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,4,2)\n",
    "plt.title('Ground Truth', fontsize=15)\n",
    "plt.imshow(msk, cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,4,3)\n",
    "plt.title('Final Thresholdded Binary Prediction (threshold > 0.5)', fontsize=15)\n",
    "plt.imshow(pred_msk_binary, cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "input_overlayed_Pred = img.copy()\n",
    "input_overlayed_Pred[pred_msk_binary == 255] = [255] \n",
    "plt.subplot(1,4,4)\n",
    "plt.title('Input Image overlayed with Prediction', fontsize=15)\n",
    "plt.imshow(input_overlayed_Pred, cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store output masks on test set in array \n",
    "masks_test = []\n",
    "for batch in batches: \n",
    "    with torch.no_grad():\n",
    "        y_pred = my_UNet(batch['scan'].cuda())\n",
    "    for i in range(2): \n",
    "        pred_msk = ((y_pred.cpu().numpy()[i][0,:,:] > 0.5) * 255).astype('uint8')\n",
    "        masks_test.append(pred_msk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recombine_slices(num_imgs):\n",
    "  start_slice = 0\n",
    "  end_slice = 36\n",
    "  for i in range(num_imgs): # loop that goes through 3D imgs\n",
    "    mask_nifti = mask_imgs[i + 71] \n",
    "\n",
    "    curr_mask = np.empty((64,64))\n",
    "\n",
    "\n",
    "    for j in range(start_slice, end_slice): # loop that goes through slices\n",
    "      mask_slice = masks_test[j]\n",
    "\n",
    "      mask_slice = np.squeeze(mask_slice)\n",
    "\n",
    "      curr_mask = np.dstack([curr_mask, mask_slice[ :, :, None]])\n",
    "\n",
    "      curr_mask = np.squeeze(curr_mask)\n",
    "\n",
    "    curr_mask = curr_mask[:,:,1:curr_mask.shape[2]]\n",
    "\n",
    "\n",
    "    curr_mask_nifti = processing.conform(nib.Nifti1Image(curr_mask, mask_nifti.affine), out_shape=curr_mask.shape)# save curr mask as a nifti at output path\n",
    "\n",
    "    mask_nifti_path = 'C:/Users/Susanna/Documents/Heart_Segmentation/output_vanilla/mask_'+  str(i + 1) + '.nii.gz'\n",
    "    nib.save(curr_mask_nifti, Path(mask_nifti_path))\n",
    "\n",
    "    start_slice += 36\n",
    "    end_slice += 36\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# recombine slices into 3D scans - 36 slices per scan \n",
    "recombine_slices(int(len(masks_test)/36))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_net(net, test_dataloader, loss_function):\n",
    "    # Create the pred_mask folder\n",
    "    \n",
    "    net.eval()\n",
    "    \n",
    "    n_test = len(test_dataloader)\n",
    "    test_batch_loss = list()\n",
    "    test_batch_dice = list()\n",
    "    test_batch_accuray = list()\n",
    "    test_batch_CM = list()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(test_dataloader):\n",
    "\n",
    "            # Load a batch \n",
    "            imgs = batch['scan'].cuda()\n",
    "            true_masks = batch['mask'].cuda()\n",
    "            img_ids = batch['img_id'].numpy().astype('int')\n",
    "\n",
    "            # Produce the estimated mask \n",
    "            y_pred = net(imgs)\n",
    "\n",
    "            # Compute the loss for this batch \n",
    "            loss = loss_function(y_pred, true_masks)\n",
    "            batch_loss = loss.item()\n",
    "            test_batch_loss.append(batch_loss)\n",
    "\n",
    "            # Make the thresholded mask \n",
    "            pred_binary = (y_pred > 0.5).float()                    \n",
    "\n",
    "            # Compute the DICE score \n",
    "            batch_dice_score = dice_coeff_binary(pred_binary, true_masks)\n",
    "            test_batch_dice.append(batch_dice_score)\n",
    "        \n",
    "            \n",
    "            # Vectorize the true mask \n",
    "            vectorize_true_masks = true_masks.view(-1).cpu().numpy()\n",
    "            vectorize_pred_masks = pred_binary.view(-1).cpu().numpy()\n",
    "            \n",
    "\n",
    "            # Print the progress\n",
    "            print(f'Test Batch {i+1}/{n_test} - DICE score: {batch_dice_score}', end='\\r')\n",
    "\n",
    "   \n",
    "    test_dice = np.array(test_batch_dice).mean()\n",
    "    \n",
    "    \n",
    "    return test_dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dice = test_net(my_UNet, test_dataloader, loss_function)\n",
    "\n",
    "print(f'Test DICE score: {test_dice}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################## Attention U-Net #################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, ch_in, ch_out):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "          nn.Conv2d(ch_in, ch_out, kernel_size=3, stride=1,padding=1, bias=True),\n",
    "          nn.BatchNorm2d(ch_out),\n",
    "          nn.ReLU(inplace=True),\n",
    "          nn.Conv2d(ch_out, ch_out,kernel_size=3, stride=1, padding=1, bias=True),\n",
    "          nn.BatchNorm2d(ch_out),\n",
    "          nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpConvBlock(nn.Module):\n",
    "    def __init__(self, ch_in, ch_out):\n",
    "        super().__init__()\n",
    "        self.up = nn.Sequential(nn.Upsample(scale_factor=2),nn.Conv2d(ch_in, ch_out,kernel_size=3,stride=1,padding=1, bias=True),\n",
    "        nn.BatchNorm2d(ch_out),\n",
    "        nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.up(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionBlock(nn.Module):\n",
    "    def __init__(self, f_g, f_l, f_int):\n",
    "        super().__init__()\n",
    "        # gating signal weights\n",
    "        self.w_g = nn.Sequential(\n",
    "            nn.Conv2d(f_g, f_int, kernel_size=1, stride=1, padding=0, bias=True), \n",
    "            nn.BatchNorm2d(f_int)\n",
    "        )\n",
    "        # input feature scaling\n",
    "        self.w_x = nn.Sequential(\n",
    "            nn.Conv2d(f_l, f_int, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "        nn.BatchNorm2d(f_int)\n",
    "        )\n",
    "\n",
    "        # output of attention gate \n",
    "        self.psi = nn.Sequential(nn.Conv2d(f_int, 1, kernel_size=1, stride=1, padding=0,  bias=True),\n",
    "        nn.BatchNorm2d(1),\n",
    "        nn.Sigmoid(),\n",
    "        )\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    # implementing the attention gate \n",
    "    def forward(self, g, x):\n",
    "        g1 = self.w_g(g)\n",
    "        x1 = self.w_x(x)\n",
    "        psi = self.relu(g1+x1)\n",
    "        psi = self.psi(psi)\n",
    "        \n",
    "        return psi*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionUNet(nn.Module):\n",
    "    def __init__(self, n_classes=1, in_channel=1, out_channel=1):\n",
    "        super().__init__() \n",
    "        \n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv1 = ConvBlock(ch_in=in_channel, ch_out=64)\n",
    "        self.conv2 = ConvBlock(ch_in=64, ch_out=128)\n",
    "        self.conv3 = ConvBlock(ch_in=128, ch_out=256)\n",
    "        self.conv4 = ConvBlock(ch_in=256, ch_out=512)\n",
    "        self.conv5 = ConvBlock(ch_in=512, ch_out=1024)\n",
    "        \n",
    "        self.up5 = UpConvBlock(ch_in=1024, ch_out=512)\n",
    "        self.att5 = AttentionBlock(f_g=512, f_l=512, f_int=256)\n",
    "        self.upconv5 = ConvBlock(ch_in=1024, ch_out=512)\n",
    "        \n",
    "        self.up4 = UpConvBlock(ch_in=512, ch_out=256)\n",
    "        self.att4 = AttentionBlock(f_g=256, f_l=256, f_int=128)\n",
    "        self.upconv4 = ConvBlock(ch_in=512, ch_out=256)\n",
    "        \n",
    "        self.up3 = UpConvBlock(ch_in=256, ch_out=128)\n",
    "        self.att3 = AttentionBlock(f_g=128, f_l=128, f_int=64)\n",
    "        self.upconv3 = ConvBlock(ch_in=256, ch_out=128)\n",
    "        \n",
    "        self.up2 = UpConvBlock(ch_in=128, ch_out=64)\n",
    "        self.att2 = AttentionBlock(f_g=64, f_l=64, f_int=32)\n",
    "        self.upconv2 = ConvBlock(ch_in=128, ch_out=64)\n",
    "        \n",
    "        self.conv_1x1 = nn.Conv2d(64, out_channel,kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # encoder\n",
    "        x1 = self.conv1(x)\n",
    "        \n",
    "        x2 = self.maxpool(x1)\n",
    "        x2 = self.conv2(x2)\n",
    "        \n",
    "        x3 = self.maxpool(x2)\n",
    "        x3 = self.conv3(x3)\n",
    "        \n",
    "        x4 = self.maxpool(x3)\n",
    "        x4 = self.conv4(x4)\n",
    "        \n",
    "        x5 = self.maxpool(x4)\n",
    "        x5 = self.conv5(x5)\n",
    "        \n",
    "        # decoder\n",
    "        d5 = self.up5(x5)\n",
    "        x4 = self.att5(g=d5, x=x4)\n",
    "        d5 = torch.concat((x4, d5), dim=1)\n",
    "        d5 = self.upconv5(d5)\n",
    "        \n",
    "        d4 = self.up4(d5)\n",
    "        x3 = self.att4(g=d4, x=x3)\n",
    "        d4 = torch.concat((x3, d4), dim=1)\n",
    "        d4 = self.upconv4(d4)\n",
    "        \n",
    "        d3 = self.up3(d4)\n",
    "        x2 = self.att3(g=d3, x=x2)\n",
    "        d3 = torch.concat((x2, d3), dim=1)\n",
    "        d3 = self.upconv3(d3)\n",
    "        \n",
    "        d2 = self.up2(d3)\n",
    "        x1 = self.att2(g=d2, x=x1)\n",
    "        d2 = torch.concat((x1, d2), dim=1)\n",
    "        d2 = self.upconv2(d2)\n",
    "        \n",
    "        d1 = self.conv_1x1(d2)\n",
    "        \n",
    "        return d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for GPU \n",
    "if torch.cuda.is_available():\n",
    "  device = torch.device(\"cuda\")\n",
    "else:\n",
    "  device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_unet = AttentionUNet(n_classes=1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show prediciton with pre trained wiehgts\n",
    "for batch in train_dataloader:\n",
    "    sample_batch = batch\n",
    "    break\n",
    "\n",
    "\n",
    "# Generat network prediction\n",
    "with torch.no_grad():\n",
    "    y_pred = attention_unet(sample_batch['image'].cuda())\n",
    "\n",
    "img = (sample_batch['image'][0].numpy().transpose(1,2,0) * 255).astype('uint8')\n",
    "msk = (sample_batch['mask'][0][0,:,:].numpy() * 255).astype('uint8')\n",
    "\n",
    "pred_msk = (y_pred.cpu().numpy()[0][0,:,:] * 255).astype('uint8')\n",
    "pred_msk_binary = ((y_pred.cpu().numpy()[0][0,:,:] > 0.5) * 255).astype('uint8')\n",
    "\n",
    "# Take the image id for display\n",
    "img_id = sample_batch['img_id'][0]\n",
    "\n",
    "plt.figure(figsize=(24,9))\n",
    "plt.suptitle(f'Test sample Image {img_id}', fontsize=18)\n",
    "\n",
    "plt.subplot(1,4,1)\n",
    "plt.title('Input Image', fontsize=15)\n",
    "plt.imshow(img,cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,4,2)\n",
    "plt.title('Ground Truth', fontsize=15)\n",
    "plt.imshow(msk, cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,4,3)\n",
    "plt.title('Non-trained Network Prediction Output \\n(probability [0, 1])', fontsize=15)\n",
    "plt.imshow(pred_msk, cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,4,4)\n",
    "plt.title('Non-trained Thresholdded Binary Prediction (threshold > 0.5)', fontsize=15)\n",
    "plt.imshow(pred_msk_binary, cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dice(model, loader, threshold=0.5):\n",
    "    valloss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "\n",
    "        for i_step, batch in enumerate(loader):\n",
    "            \n",
    "            data = batch['scan'].cuda()\n",
    "            target = batch['mask'].cuda()\n",
    "            \n",
    "            outputs = model(data)\n",
    "\n",
    "            out_cut = np.copy(outputs.data.cpu().numpy())\n",
    "            out_cut[np.nonzero(out_cut < threshold)] = 0.0\n",
    "            out_cut[np.nonzero(out_cut >= threshold)] = 1.0\n",
    "            picloss = dice_coeff_binary(out_cut, target.data.cpu().numpy())\n",
    "            valloss += picloss\n",
    "\n",
    "    return valloss / i_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_name, model, train_loader, val_loader, train_loss, optimizer, lr_scheduler, num_epochs):    \n",
    "    loss_history = []\n",
    "    train_history = []\n",
    "    val_history = []\n",
    "    val_loss_history = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        \n",
    "        losses = []\n",
    "        train_iou = []\n",
    "        \n",
    "        for i_step, batch in enumerate(tqdm(train_loader)):\n",
    "            \n",
    "            data = batch['scan'].cuda()\n",
    "            target = batch['mask'].cuda()\n",
    "            \n",
    "            outputs = model(data)\n",
    "            \n",
    "            out_cut = np.copy(outputs.data.cpu().numpy())\n",
    "            out_cut[np.nonzero(out_cut < 0.5)] = 0.0\n",
    "            out_cut[np.nonzero(out_cut >= 0.5)] = 1.0\n",
    "            \n",
    "            train_dice = dice_coeff_binary(out_cut, target.data.cpu().numpy())\n",
    "            \n",
    "            loss = train_loss(outputs, target)\n",
    "            \n",
    "            losses.append(loss.item())\n",
    "            train_iou.append(train_dice)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        val_mean_iou = compute_dice(model, val_loader)\n",
    "        val_loss = train_loss(outputs, target)\n",
    "        loss_history.append(np.array(losses).mean())\n",
    "        train_history.append(np.array(train_iou).mean())\n",
    "        val_history.append(val_mean_iou)\n",
    "        val_loss_history.append(val_loss.item())\n",
    "        \n",
    "        print(\"Epoch [%d]\" % (epoch+1))\n",
    "        print(\"Training loss :\", np.array(losses).mean(), \n",
    "              \"DICE score training:\", np.array(train_iou).mean(), \n",
    "              \"DICE score validation\", val_mean_iou,\n",
    "              \"Validation loss:\", np.array(val_loss_history).mean())\n",
    "        \n",
    "    return loss_history, train_history, val_history, val_loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.Adamax(attention_unet.parameters(), lr=1e-3) # use Adam optimizer \n",
    "loss_function = nn.BCELoss() # use BCE loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ep = 30\n",
    "aun_lh, aun_th, aun_vh, aun_vl = train_model(\"Attention UNet\", attention_unet, train_dataloader, valid_dataloader, loss_function, opt, False, num_ep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get test DICE score \n",
    "test_iou = get_dice(attention_unet, test_dataloader)\n",
    "print(f\"\"\"Test DICE  - {test_iou}%\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model output \n",
    "batches = []\n",
    "\n",
    "test_num = 0\n",
    "\n",
    "for batch in test_dataloader:\n",
    "    sample_batch = batch\n",
    "    batches.append(batch)\n",
    "\n",
    "sample_batch = batches[3] #0\n",
    "\n",
    "# Generat network prediction\n",
    "with torch.no_grad():\n",
    "    y_pred = attention_unet(sample_batch['image'].cuda())\n",
    "\n",
    "\n",
    "img = (sample_batch['image'][0].numpy().transpose(1,2,0) * 255).astype('uint8')\n",
    "msk = (sample_batch['mask'][0][0,:,:].numpy() * 255).astype('uint8')\n",
    "\n",
    "pred_msk = (y_pred.cpu().numpy()[0][0,:,:] * 255).astype('uint8')\n",
    "pred_msk_binary = ((y_pred.cpu().numpy()[0][0,:,:] > 0.5) * 255).astype('uint8')\n",
    "\n",
    "# Take the image id for display\n",
    "img_id = sample_batch['img_id'][0]\n",
    "\n",
    "plt.figure(figsize=(24,9))\n",
    "plt.suptitle(f'Test sample Image {img_id}', fontsize=18)\n",
    "\n",
    "plt.subplot(1,4,1)\n",
    "plt.title('Input Image', fontsize=15)\n",
    "plt.imshow(img,cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,4,2)\n",
    "plt.title('Ground Truth', fontsize=15)\n",
    "plt.imshow(msk, cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,4,3)\n",
    "plt.title('Non-trained Thresholdded Binary Prediction (threshold > 0.5)', fontsize=15)\n",
    "plt.imshow(pred_msk_binary, cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store output masks in array\n",
    "masks_test = []\n",
    "for batch in batches: \n",
    "    with torch.no_grad():\n",
    "        y_pred = attention_unet(batch['image'].cuda())\n",
    "    for i in range(2): \n",
    "        pred_msk = ((y_pred.cpu().numpy()[0][0,:,:] > 0.5) * 255).astype('uint8')\n",
    "        # print(pred_msk.shape)\n",
    "        # print(type(pred_msk))\n",
    "        masks_test.append(pred_msk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recombine slices into full scans \n",
    "#recombine_slices(int(len(masks_test)/36))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
