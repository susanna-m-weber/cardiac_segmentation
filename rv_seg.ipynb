{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ef4fe5-9f8d-4852-af24-07bf343842d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "from nibabel import processing\n",
    "\n",
    "from skimage import io\n",
    "from skimage.transform import resize\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import warnings\n",
    "import shutil\n",
    "\n",
    "import SimpleITK as sitk\n",
    "# from nipype.interfaces.ants import N4BiasFieldCorrection\n",
    "from scipy import misc\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "import re\n",
    "import PIL\n",
    "import cv2\n",
    "from torchvision.transforms import v2\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import copy\n",
    "from PIL import Image, ImageDraw\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713bc10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of sources used for this notebook: \n",
    "# BMEN 4460 Lecture 7 \n",
    "# https://www.kaggle.com/c/second-annual-data-science-bowl/data\n",
    "# https://www.kaggle.com/code/truthisneverlinear/attention-u-net-pytorch \n",
    "# https://github.com/ozan-oktay/Attention-Gated-Networks \n",
    "# https://github.com/chuckyee/cardiac-segmentation/tree/master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1489e7b9-ba1d-4ebf-9e56-2e4b9ac55e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for GPU \n",
    "if torch.cuda.is_available():\n",
    "  device = torch.device(\"cuda\")\n",
    "else:\n",
    "  device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6349ef7-0b21-46bf-81ec-eba2259e447c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data directories\n",
    "data_root_folder = Path(\"C:/Users/Susanna/Documents/myocardium_segmentation/data\")\n",
    "\n",
    "scan_slices_train_dir = Path(\"C:/Users/Susanna/Documents/myocardium_segmentation/data/train/scan/\")\n",
    "endo_mask_slices_train_dir = Path(\"C:/Users/Susanna/Documents/myocardium_segmentation/data/train/endo_mask/\")\n",
    "epi_mask_slices_train_dir = Path(\"C:/Users/Susanna/Documents/myocardium_segmentation/data/train/epi_mask/\")\n",
    "\n",
    "scan_slices_valid_dir = Path(\"C:/Users/Susanna/Documents/myocardium_segmentation/data/valid/scan/\")\n",
    "endo_mask_slices_valid_dir = Path(\"C:/Users/Susanna/Documents/myocardium_segmentation/data/valid/endo_mask/\")\n",
    "epi_mask_slices_valid_dir = Path(\"C:/Users/Susanna/Documents/myocardium_segmentation/data/valid/epi_mask/\")\n",
    "\n",
    "scan_slices_valid_dir = Path(\"C:/Users/Susanna/Documents/myocardium_segmentation/data/test/scan/\")\n",
    "endo_mask_slices_valid_dir = Path(\"C:/Users/Susanna/Documents/myocardium_segmentation/data/test/endo_mask/\")\n",
    "epi_mask_slices_valid_dir = Path(\"C:/Users/Susanna/Documents/myocardium_segmentation/data/test/epi_mask/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e654006d-8569-4730-a620-3e24492f7260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# have a look at data for sanity check \n",
    "test_num = 45\n",
    "test_scan = os.path.join(scan_slices_train_dir, f\"scan_{test_num}.png\")\n",
    "test_mask = os.path.join(endo_mask_slices_train_dir, f\"mask_{test_num}.png\")\n",
    "data_scan = PIL.Image.open(test_scan)\n",
    "data_scan_arr = np.array(data_scan)\n",
    "\n",
    "data_mask = PIL.Image.open(test_mask)\n",
    "data_mask_arr = np.array(data_mask)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(data_scan_arr, cmap=plt.cm.gray)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(data_mask_arr, cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71771ad6-d0d0-4e8e-ad64-e4944fa61137",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root_folder = Path(\"C:/Users/Susanna/Documents/myocardium_segmentation/data\")\n",
    "class BasicDataset(TensorDataset):\n",
    "    # retrieve files from folder \n",
    "    def __init__(self, folder, mask_type, n_sample=None, transform=None):\n",
    "        self.folder = os.path.join(data_root_folder, folder)\n",
    "        self.imgs_dir = os.path.join(self.folder, 'scan')\n",
    "        self.masks_dir = os.path.join(self.folder, f'{mask_type}_mask')\n",
    "        self.imgs_file = sorted(glob.glob(os.path.join(self.imgs_dir, '*.png')))\n",
    "        self.masks_file = sorted(glob.glob(os.path.join(self.masks_dir, '*.png')))\n",
    "        \n",
    "        assert len(self.imgs_file) == len(self.masks_file), 'There are some missing images or masks in {0}'.format(folder)\n",
    "        \n",
    "        # If n_sample is not None (It has been set by the user)\n",
    "        if not n_sample or n_sample > len(self.imgs_file):\n",
    "            n_sample = len(self.imgs_file)\n",
    "        \n",
    "        self.n_sample = n_sample\n",
    "        self.ids = list([i+1 for i in range(n_sample)])\n",
    "        self.transform = transform\n",
    "            \n",
    "    # Return length of dataset\n",
    "    def __len__(self):\n",
    "        return self.n_sample\n",
    "    \n",
    "    \n",
    "        # return scan, corresponding mask, and the file index \n",
    "    def __getitem__(self, i):\n",
    "        idx = self.ids[i]\n",
    "        \n",
    "        img = cv2.imread(os.path.join(self.imgs_dir, 'scan_{:}.png'.format(idx)), cv2.IMREAD_GRAYSCALE)\n",
    "        mask = cv2.imread(os.path.join(self.masks_dir, 'mask_{:}.png'.format(idx)), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        # normalize scans and masks \n",
    "        img = np.array(img) / 255.0\n",
    "        mask = np.array(mask) / 255.0\n",
    "\n",
    "        # binarize mask \n",
    "        mask[mask <= 0.5] = 0.0\n",
    "        mask[mask > 0.5] = 1.0        \n",
    "\n",
    "        # data augmentation\n",
    "        if self.transform is not None:\n",
    "            augmented = self.transform(image=img, mask=mask)\n",
    "            img = augmented[\"image\"]\n",
    "            mask = augmented[\"mask\"]\n",
    "\n",
    "        # resive from 512x216 \n",
    "        img = cv2.resize(img, (128,128))\n",
    "        mask = cv2.resize(mask, (128,128))\n",
    "        \n",
    "        # Add an axis to the mask array so that it is in [channel, width, height] format.\n",
    "        mask = np.expand_dims(mask, axis=0)\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        \n",
    "        img = img.copy()\n",
    "        mask = mask.copy()\n",
    "        return {\n",
    "            'image': torch.from_numpy(img).type(torch.FloatTensor),\n",
    "            'mask': torch.from_numpy(mask).type(torch.FloatTensor),\n",
    "            'img_id': idx\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91f6869-590e-4bd4-a6ba-568a78e7463e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image transformations \n",
    "transforms = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "], is_check_shapes=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7575f7d6-6ac2-40a7-8be5-09140de0348f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train, validation, and test dataset instances - RV segmentation \n",
    "train_dataset = BasicDataset('train', 'epi', transform=transforms) #change 'epi' to 'endo' to train on endocardium contrours instead \n",
    "valid_dataset = BasicDataset('valid', 'epi', transform=transforms)\n",
    "test_dataset = BasicDataset('test', 'epi', transform=transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7449dc4-ba12-4dbd-bf5d-0d3cc5910efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize a scan and corresponding mask for sanity check, make sure dataloader is transforming scans and masks together\n",
    "sample = np.random.randint(0, len(train_dataset))\n",
    "data = train_dataset.__getitem__(sample)\n",
    "x = data['image']\n",
    "y = data['mask']\n",
    "idx = data['img_id']\n",
    "\n",
    "plt.figure(figsize=(12, 8), dpi=100)\n",
    "plt.suptitle(f'Sample {idx}')\n",
    "img = x[0]\n",
    "mask = y[0]\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Image')\n",
    "plt.imshow(img,  cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('Mask')\n",
    "plt.imshow(mask, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d138ee-66a4-4110-be41-1329a242a86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=0, pin_memory=True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=2, num_workers=0, pin_memory=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=2, num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0f5045-0b9a-49be-beab-5a9f1dd77f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################## Standard U-Net #################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54618bd4-579e-4a58-9838-6705afd8ba1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "    \n",
    "class Down(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "class Up(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.up_conv = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1, padding=0),\n",
    "        ) \n",
    "        self.conv = DoubleConv(out_channels * 2, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up_conv(x1)\n",
    "        x = torch.cat([x1, x2], dim=1)\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv_sigmoid = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv_sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabc4ae0-51bc-4cb1-a7f0-2fb36469921b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, name, n_channels, n_classes):\n",
    "        super(UNet, self).__init__()\n",
    "        self.name = name\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "        self.inputL = DoubleConv(n_channels, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.down3 = Down(256, 512)\n",
    "        self.down4 = Down(512, 1024)\n",
    "        self.up1 = Up(1024, 512)\n",
    "        self.up2 = Up(512, 256)\n",
    "        self.up3 = Up(256, 128)\n",
    "        self.up4 = Up(128, 64)\n",
    "        self.outputL = OutConv(64, n_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x0 = self.inputL(x)\n",
    "        \n",
    "        x1 = self.down1(x0)\n",
    "        x2 = self.down2(x1)\n",
    "        x3 = self.down3(x2)\n",
    "        x4 = self.down4(x3)\n",
    "        \n",
    "        x = self.up1(x4, x3)\n",
    "        x = self.up2(x, x2)\n",
    "        x = self.up3(x, x1)\n",
    "        x = self.up4(x, x0)\n",
    "        \n",
    "        x = self.outputL(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f73abd3-d526-46f6-9c17-e37d4122fafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model, set number of channels in and channels out \n",
    "myocard_UNet = UNet('MyUNet', n_channels=1, n_classes=1)\n",
    "myocard_UNet.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2a01a2-270e-45c0-8666-3f3277ab8ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre trained weights from whole heart segmentation using U-NEt\n",
    "model_path = Path(\"C:\\\\Users\\\\Susanna\\\\Documents\\\\stored_models\\\\2d_unet.pth\")\n",
    "myocard_UNet.load_state_dict(torch.load(model_path))\n",
    "myocard_UNet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30760954-1497-49fb-afc3-abf58ceb84a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize pre-trained model\n",
    "for batch in train_dataloader:\n",
    "    sample_batch = batch\n",
    "    break\n",
    "    \n",
    "# Generat network prediction\n",
    "with torch.no_grad():\n",
    "    y_pred = myocard_UNet(sample_batch['image'].cuda())\n",
    "\n",
    "img = (sample_batch['image'][0].numpy().transpose(1,2,0) * 255).astype('uint8')\n",
    "msk = (sample_batch['mask'][0][0,:,:].numpy() * 255).astype('uint8')\n",
    "\n",
    "pred_msk = (y_pred.cpu().numpy()[0][0,:,:] * 255).astype('uint8')\n",
    "pred_msk_binary = ((y_pred.cpu().numpy()[0][0,:,:] > 0.5) * 255).astype('uint8')\n",
    "\n",
    "# Take the image id for display\n",
    "img_id = sample_batch['img_id'][0]\n",
    "\n",
    "plt.figure(figsize=(24,9))\n",
    "plt.suptitle(f'Test sample Image {img_id}', fontsize=18)\n",
    "\n",
    "plt.subplot(1,4,1)\n",
    "plt.title('Input Image', fontsize=15)\n",
    "plt.imshow(img,cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,4,2)\n",
    "plt.title('Ground Truth', fontsize=15)\n",
    "plt.imshow(msk, cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,4,3)\n",
    "plt.title('Non-trained Network Prediction Output ', fontsize=15)\n",
    "plt.imshow(pred_msk, cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,4,4)\n",
    "plt.title('Non-trained Thresholdded Binary Prediction ', fontsize=15)\n",
    "plt.imshow(pred_msk_binary, cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aead248-06b3-4eca-9adc-2ee4064ed7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(myocard_UNet.parameters(), lr=0.001) # using Adam optimizer with learning rate of 0.001\n",
    "loss_function = nn.BCELoss() # using binary cross entropy loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f57b65-41cb-4715-a87e-8d5ad17690e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that computes the DICE score for binary segmentation\n",
    "def dice_coeff_binary(y_pred, y_true):\n",
    "    \"\"\"Values must be only zero or one.\"\"\"\n",
    "    eps = 0.0001\n",
    "    inter = torch.dot(y_pred.view(-1), y_true.view(-1))\n",
    "    union = torch.sum(y_pred) + torch.sum(y_true)\n",
    "    return ((2 * inter.float() + eps) / (union.float() + eps)).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4d9f17-fd11-4702-9868-127a56353b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The training function\n",
    "def train_net(net, epochs, train_dataloader, valid_dataloader, optimizer, loss_function):\n",
    "    \n",
    "    if not os.path.isdir('{0}'.format(net.name)):\n",
    "        os.mkdir('{0}'.format(net.name))\n",
    "    \n",
    "    n_train = len(train_dataloader)\n",
    "    n_valid = len(valid_dataloader)    \n",
    "    \n",
    "    train_loss = list()\n",
    "    valid_loss = list()\n",
    "    train_dice = list()\n",
    "    valid_dice = list()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        net.train()\n",
    "        train_batch_loss = list()\n",
    "        train_batch_dice = list()\n",
    "        \n",
    "        for i, batch in enumerate(train_dataloader):\n",
    "            # Load a batch \n",
    "            imgs = batch['image'].cuda()\n",
    "            true_masks = batch['mask'].cuda()\n",
    "\n",
    "            # Produce the estimated mask from model\n",
    "            y_pred = net(imgs)\n",
    "\n",
    "            # Compute the loss for the batch\n",
    "            loss = loss_function(y_pred, true_masks)\n",
    "            batch_loss = loss.item()\n",
    "            train_batch_loss.append(batch_loss)\n",
    "\n",
    "            # Make the thresholded mask to compute the DICE score\n",
    "            pred_binary = (y_pred > 0.5).float()                   \n",
    "            \n",
    "            # Compute the DICE score for batch \n",
    "            batch_dice_score = dice_coeff_binary(pred_binary, true_masks)\n",
    "            train_batch_dice.append(batch_dice_score)\n",
    "            \n",
    "            # Reset gradient values\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Compute the backward losses\n",
    "            loss.backward()\n",
    "\n",
    "            # Update the weights\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Print the progress\n",
    "            print(f'EPOCH {epoch + 1}/{epochs} - Training Batch {i+1}/{n_train} - Loss: {batch_loss}, DICE score: {batch_dice_score}', end='\\r')\n",
    "        \n",
    "        average_training_loss = np.array(train_batch_loss).mean()\n",
    "        average_training_dice = np.array(train_batch_dice).mean()\n",
    "        train_loss.append(average_training_loss)\n",
    "        train_dice.append(average_training_dice)\n",
    "\n",
    "        # validation \n",
    "        net.eval()\n",
    "        valid_batch_loss = list()\n",
    "        valid_batch_dice = list()\n",
    "        \n",
    "        # set layers to evaluation mode\n",
    "        # don't need to calculate the gradient \n",
    "        # speeds up evaluation \n",
    "        with torch.no_grad():\n",
    "            for i, batch in enumerate(valid_dataloader):\n",
    "\n",
    "                imgs = batch['image'].cuda()\n",
    "                true_masks = batch['mask'].cuda()\n",
    "\n",
    "                y_pred = net(imgs)\n",
    "\n",
    "                loss = loss_function(y_pred, true_masks)\n",
    "                batch_loss = loss.item()\n",
    "                valid_batch_loss.append(batch_loss)\n",
    "\n",
    "                pred_binary = (y_pred > 0.5).float()                    \n",
    "\n",
    "                batch_dice_score = dice_coeff_binary(pred_binary, true_masks)\n",
    "                valid_batch_dice.append(batch_dice_score)\n",
    "\n",
    "                # Print the progress\n",
    "                print(f'EPOCH {epoch + 1}/{epochs} - Validation Batch {i+1}/{n_valid} - Loss: {batch_loss}, DICE score: {batch_dice_score}', end='\\r')\n",
    "                \n",
    "        average_validation_loss = np.array(valid_batch_loss).mean()\n",
    "        average_validation_dice = np.array(valid_batch_dice).mean()\n",
    "        valid_loss.append(average_validation_loss)\n",
    "        valid_dice.append(average_validation_dice)\n",
    "        \n",
    "        print(f'EPOCH {epoch + 1}/{epochs} - Training Loss: {average_training_loss}, Training DICE score: {average_training_dice}, Validation Loss: {average_validation_loss}, Validation DICE score: {average_validation_dice}')\n",
    "    \n",
    "    return train_loss, train_dice, valid_loss, valid_dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681c969f-26d8-431e-a6c4-61a1e46367b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 30 \n",
    "train_loss, train_dice, valid_loss, valid_dice = train_net(myocard_UNet, EPOCHS, train_dataloader, valid_dataloader, optimizer, loss_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f81b49-18e7-438d-a951-48725b0d9009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print training curves \n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.suptitle('Learning Curve', fontsize=18)\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(np.arange(EPOCHS)+1, train_loss, '-o', label='Training Loss')\n",
    "plt.plot(np.arange(EPOCHS)+1, valid_loss, '-o', label='Validation Loss')\n",
    "#plt.xticks(np.arange(EPOCHS)+1)\n",
    "plt.xlabel('Epoch', fontsize=15)\n",
    "plt.ylabel('Loss', fontsize=15)\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(np.arange(EPOCHS)+1, train_dice, '-o', label='Training DICE score')\n",
    "plt.plot(np.arange(EPOCHS)+1, valid_dice, '-o', label='Validation DICE score')\n",
    "plt.ylim(0.5,0.95)\n",
    "#plt.xticks(np.arange(EPOCHS)+1)\n",
    "plt.xlabel('Epoch', fontsize=15)\n",
    "plt.ylabel('DICE score', fontsize=15)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c522aa87-806c-439b-934b-e17331d2ecc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display test mask results \n",
    "\n",
    "batches = []\n",
    "test_num = 0\n",
    "\n",
    "for batch in test_dataloader:\n",
    "    sample_batch = batch\n",
    "    batches.append(batch)\n",
    "\n",
    "sample_batch = batches[0] \n",
    "\n",
    "# Generate network prediction\n",
    "with torch.no_grad():\n",
    "    y_pred = myocard_UNet(sample_batch['image'].cuda())\n",
    "\n",
    "\n",
    "test_num = 1 #0 #1\n",
    "# Conver Pytorch tensor to numpy array then reverse the preprocessing steps\n",
    "img = (sample_batch['image'][test_num].numpy().transpose(1,2,0) * 255).astype('uint8')\n",
    "msk = (sample_batch['mask'][test_num][0,:,:].numpy() * 255).astype('uint8')\n",
    "\n",
    "# Exctract the relative prediction mask and threshold the probablities (>0.5)\n",
    "pred_msk = (y_pred.cpu().numpy()[test_num][0,:,:] * 255).astype('uint8')\n",
    "pred_msk_binary = ((y_pred.cpu().numpy()[test_num][0,:,:] > 0.5) * 255).astype('uint8')\n",
    "\n",
    "# Take the image id for display\n",
    "img_id = sample_batch['img_id'][0]\n",
    "\n",
    "plt.figure(figsize=(24,9))\n",
    "plt.suptitle(f'Test sample Image {img_id}', fontsize=18)\n",
    "\n",
    "plt.subplot(1,4,1)\n",
    "plt.title('Input Image', fontsize=15)\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,4,2)\n",
    "plt.title('Ground Truth', fontsize=15)\n",
    "plt.imshow(msk, cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,4,3)\n",
    "plt.title('Final Thresholdded Binary Prediction (threshold > 0.5)', fontsize=15)\n",
    "plt.imshow(pred_msk_binary, cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "input_overlayed_Pred = img.copy()\n",
    "input_overlayed_Pred[pred_msk_binary == 255] = [255] \n",
    "plt.subplot(1,4,4)\n",
    "plt.title('Input Image overlayed with Prediction', fontsize=15)\n",
    "plt.imshow(input_overlayed_Pred, cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52ee7c8-e00d-412e-b63a-37a485e33660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store test data predictions in array \n",
    "masks_test = []\n",
    "for batch in batches: \n",
    "    with torch.no_grad():\n",
    "        y_pred = myocard_UNet(batch['image'].cuda())\n",
    "    for i in range(4): \n",
    "        pred_msk = ((y_pred.cpu().numpy()[0][0,:,:] > 0.5) * 255).astype('uint8')\n",
    "\n",
    "        masks_test.append(pred_msk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5607b8-36c6-45d8-8d55-08c4ce3035bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store test data predictions as files \n",
    "def store_outputs(masks, store_dir):\n",
    "    ind = 0\n",
    "    for i in range(len(masks)): # loop that goes through 3D imgs\n",
    "        im_to_save = Image.fromarray(masks[i])\n",
    "        if im_to_save.mode != 'RGB':\n",
    "            im_to_save = im_to_save.convert('RGB')\n",
    "        file_name = f\"mask_{ind+1}.png\"\n",
    "        mask_dir = os.path.join(store_dir, \"_masks\")\n",
    "        im_to_save.save(os.path.join(store_dir, file_name))\n",
    "        ind += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7644192-add3-4977-bd2f-3ce066bf4d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to get mask from folder \n",
    "def get_mask(ind, folder): \n",
    "    mask_file = os.path.join(folder, f\"mask_{ind+1}.png\")\n",
    "    mask_img = PIL.Image.open(mask_file)\n",
    "    mask_arr = np.array(mask_img)\n",
    "    return mask_arr, mask_img, mask_file\n",
    "\n",
    "# helper function to get img from folder \n",
    "def get_img(ind, folder): \n",
    "    mask_file = os.path.join(folder, f\"scan_{ind+1}.png\")\n",
    "    mask_img = PIL.Image.open(mask_file)\n",
    "    mask_arr = np.array(mask_img)\n",
    "    return mask_arr, mask_img, mask_file\n",
    "\n",
    "# helper function to get contour from folder\n",
    "def get_contour(ind, folder): \n",
    "    mask_file = os.path.join(folder, f\"contour_{ind+1}.png\")\n",
    "    mask_img = PIL.Image.open(mask_file)\n",
    "    mask_arr = np.array(mask_img)\n",
    "    return mask_arr, mask_img, mask_file\n",
    "\n",
    "# atore contours generated from mask\n",
    "def store_contours(masks, masks_dir, store_dir):\n",
    "    for i in range(len(masks)):\n",
    "        mask_arr, mask_img, mask_file = get_mask(i, masks_dir)\n",
    "        contour = cv2.imread(mask_file)\n",
    "        contour_gray = cv2.cvtColor(contour,cv2.COLOR_BGR2GRAY)\n",
    "        ret,thresh = cv2.threshold(contour_gray,127,255,0)\n",
    "        contours, hierarchy = cv2.findContours(thresh,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\n",
    "        tmp = np.zeros_like(contour)\n",
    "        boundary = cv2.drawContours(tmp, contours, -1, (255,255,255), 1)\n",
    "        boundary[boundary > 0] = 255\n",
    "        file_name_contour = f\"contour_{i+1}.png\"\n",
    "        plt.imsave(os.path.join(store_dir, file_name_contour), boundary, cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1137c1-f697-4f55-a29e-16910f392faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir_unet = Path(\"C:/Users/Susanna/Documents/myocardium_segmentation/outputs/u_net/epicardium/masks_augment\")\n",
    "output_dir_attn = Path(\"C:/Users/Susanna/Documents/myocardium_segmentation/outputs/attention_u_net/epicardium/masks_augment\")\n",
    "\n",
    "contours_unet =  Path(\"C:/Users/Susanna/Documents/myocardium_segmentation/outputs/u_net/epicardium/contours_augment\")\n",
    "contours_attn = Path(\"C:/Users/Susanna/Documents/myocardium_segmentation/outputs/attention_u_net/epicardium/contours_augment\")\n",
    "\n",
    "img_dir = Path(\"C:/Users/Susanna/Documents/myocardium_segmentation/data/test/scan/\")\n",
    "gt_dir = Path(\"C:/Users/Susanna/Documents/myocardium_segmentation/data/test/epi_mask/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00b71a2-23c0-4541-a1a4-9743617d522c",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_outputs(masks_test, output_dir_unet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f98a2a-59e0-408a-8d58-801795a5e7ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "store_contours(masks_test, output_dir_unet, contours_unet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce3860e-6ba3-4768-811b-6da3f6e931c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_net(net, test_dataloader, loss_function):\n",
    "    # Create the pred_mask folder\n",
    "    \n",
    "    net.eval()\n",
    "    \n",
    "    n_test = len(test_dataloader)\n",
    "    test_batch_loss = list()\n",
    "    test_batch_dice = list()\n",
    "    test_batch_accuray = list()\n",
    "    test_batch_CM = list()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(test_dataloader):\n",
    "\n",
    "            # Load a batch and pass it to the GPU\n",
    "            imgs = batch['image'].cuda()\n",
    "            true_masks = batch['mask'].cuda()\n",
    "            img_ids = batch['img_id'].numpy().astype('int')\n",
    "\n",
    "            # prediction\n",
    "            y_pred = net(imgs)\n",
    "\n",
    "            # Compute the loss for this batch and append it to the epoch loss\n",
    "            loss = loss_function(y_pred, true_masks)\n",
    "            batch_loss = loss.item()\n",
    "            test_batch_loss.append(batch_loss)\n",
    "\n",
    "            # Make the thresholded mask to compute the DICE score\n",
    "            pred_binary = (y_pred > 0.5).float()                    \n",
    "\n",
    "            # Compute the DICE score \n",
    "            batch_dice_score = dice_coeff_binary(pred_binary, true_masks)\n",
    "            test_batch_dice.append(batch_dice_score)\n",
    "     \n",
    "    test_dice = np.array(test_batch_dice).mean()\n",
    "\n",
    "    return  test_dice "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73f316f-3696-49c1-9de7-616c547145f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get test dice score\n",
    "test_dice= test_net(myocard_UNet, test_dataloader, loss_function)\n",
    "\n",
    "print(f' Test DICE score: {test_dice}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe066ee-a943-4577-8fb6-c596a90ccc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################# Attention U-Net ############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41f9569-7a61-40a5-833e-a4b26ed6163f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, ch_in, ch_out):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "          nn.Conv2d(ch_in, ch_out, kernel_size=3, stride=1,padding=1, bias=True),\n",
    "          nn.BatchNorm2d(ch_out),\n",
    "          nn.ReLU(inplace=True),\n",
    "          nn.Conv2d(ch_out, ch_out,kernel_size=3, stride=1, padding=1, bias=True),\n",
    "          nn.BatchNorm2d(ch_out),\n",
    "          nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfde1be3-4552-4cea-aec0-b0408e7bba77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpConvBlock(nn.Module):\n",
    "    def __init__(self, ch_in, ch_out):\n",
    "        super().__init__()\n",
    "        self.up = nn.Sequential(nn.Upsample(scale_factor=2),nn.Conv2d(ch_in, ch_out,kernel_size=3,stride=1,padding=1, bias=True),\n",
    "        nn.BatchNorm2d(ch_out),\n",
    "        nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.up(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd292e7-1814-4b23-b4dc-9a570cade1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionBlock(nn.Module):\n",
    "    def __init__(self, f_g, f_l, f_int):\n",
    "        super().__init__()\n",
    "        # gating signal weights\n",
    "        self.w_g = nn.Sequential(\n",
    "            nn.Conv2d(f_g, f_int, kernel_size=1, stride=1, padding=0, bias=True), \n",
    "            nn.BatchNorm2d(f_int)\n",
    "        )\n",
    "        # input feature scaling\n",
    "        self.w_x = nn.Sequential(\n",
    "            nn.Conv2d(f_l, f_int, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(f_int) \n",
    "        )\n",
    "\n",
    "        # output of attention gate \n",
    "        self.psi = nn.Sequential(nn.Conv2d(f_int, 1, kernel_size=1, stride=1, padding=0,  bias=True),\n",
    "        nn.BatchNorm2d(1),\n",
    "        nn.Sigmoid(),\n",
    "        )\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    # implementing the attention gate \n",
    "    def forward(self, g, x):\n",
    "        g1 = self.w_g(g)\n",
    "        x1 = self.w_x(x)\n",
    "        psi = self.relu(g1+x1)\n",
    "        psi = self.psi(psi)\n",
    "        \n",
    "        return psi*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8443ed22-d98e-43c0-8521-90b2c176e7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionUNet(nn.Module):\n",
    "    def __init__(self, n_classes=1, in_channel=1, out_channel=1):\n",
    "        super().__init__() \n",
    "        \n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv1 = ConvBlock(ch_in=in_channel, ch_out=64)\n",
    "        self.conv2 = ConvBlock(ch_in=64, ch_out=128)\n",
    "        self.conv3 = ConvBlock(ch_in=128, ch_out=256)\n",
    "        self.conv4 = ConvBlock(ch_in=256, ch_out=512)\n",
    "        self.conv5 = ConvBlock(ch_in=512, ch_out=1024)\n",
    "        \n",
    "        self.up5 = UpConvBlock(ch_in=1024, ch_out=512)\n",
    "        self.att5 = AttentionBlock(f_g=512, f_l=512, f_int=256)\n",
    "        self.upconv5 = ConvBlock(ch_in=1024, ch_out=512)\n",
    "        \n",
    "        self.up4 = UpConvBlock(ch_in=512, ch_out=256)\n",
    "        self.att4 = AttentionBlock(f_g=256, f_l=256, f_int=128)\n",
    "        self.upconv4 = ConvBlock(ch_in=512, ch_out=256)\n",
    "        \n",
    "        self.up3 = UpConvBlock(ch_in=256, ch_out=128)\n",
    "        self.att3 = AttentionBlock(f_g=128, f_l=128, f_int=64)\n",
    "        self.upconv3 = ConvBlock(ch_in=256, ch_out=128)\n",
    "        \n",
    "        self.up2 = UpConvBlock(ch_in=128, ch_out=64)\n",
    "        self.att2 = AttentionBlock(f_g=64, f_l=64, f_int=32)\n",
    "        self.upconv2 = ConvBlock(ch_in=128, ch_out=64)\n",
    "        \n",
    "        self.conv_1x1 = nn.Conv2d(64, out_channel,\n",
    "                                  kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # encoder\n",
    "        x1 = self.conv1(x)\n",
    "        \n",
    "        x2 = self.maxpool(x1)\n",
    "        x2 = self.conv2(x2)\n",
    "        \n",
    "        x3 = self.maxpool(x2)\n",
    "        x3 = self.conv3(x3)\n",
    "        \n",
    "        x4 = self.maxpool(x3)\n",
    "        x4 = self.conv4(x4)\n",
    "        \n",
    "        x5 = self.maxpool(x4)\n",
    "        x5 = self.conv5(x5)\n",
    "        \n",
    "        # decoder + concat\n",
    "        d5 = self.up5(x5)\n",
    "        x4 = self.att5(g=d5, x=x4)\n",
    "        d5 = torch.concat((x4, d5), dim=1)\n",
    "        d5 = self.upconv5(d5)\n",
    "        \n",
    "        d4 = self.up4(d5)\n",
    "        x3 = self.att4(g=d4, x=x3)\n",
    "        d4 = torch.concat((x3, d4), dim=1)\n",
    "        d4 = self.upconv4(d4)\n",
    "        \n",
    "        d3 = self.up3(d4)\n",
    "        x2 = self.att3(g=d3, x=x2)\n",
    "        d3 = torch.concat((x2, d3), dim=1)\n",
    "        d3 = self.upconv3(d3)\n",
    "        \n",
    "        d2 = self.up2(d3)\n",
    "        x1 = self.att2(g=d2, x=x1)\n",
    "        d2 = torch.concat((x1, d2), dim=1)\n",
    "        d2 = self.upconv2(d2)\n",
    "        \n",
    "        d1 = self.conv_1x1(d2)\n",
    "        \n",
    "        return d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07251b3-3bce-41db-8f5d-7ea5a89e0739",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_unet_myocard = AttentionUNet(n_classes=1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117ac862-f5a9-4c86-8500-983a6d00ee5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_unet_myocard.load_state_dict(torch.load('attention_unet.pth')) \n",
    "attention_unet_myocard.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809e8452-f59a-4927-9638-16aa39e61e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show prediciton with pre trained wiehgts\n",
    "for batch in train_dataloader:\n",
    "    sample_batch = batch\n",
    "    break\n",
    "\n",
    "\n",
    "# Generat network prediction\n",
    "with torch.no_grad():\n",
    "    y_pred = myocard_UNet(sample_batch['image'].cuda())\n",
    "\n",
    "img = (sample_batch['image'][0].numpy().transpose(1,2,0) * 255).astype('uint8')\n",
    "msk = (sample_batch['mask'][0][0,:,:].numpy() * 255).astype('uint8')\n",
    "\n",
    "pred_msk = (y_pred.cpu().numpy()[0][0,:,:] * 255).astype('uint8')\n",
    "pred_msk_binary = ((y_pred.cpu().numpy()[0][0,:,:] > 0.5) * 255).astype('uint8')\n",
    "\n",
    "# Take the image id for display\n",
    "img_id = sample_batch['img_id'][0]\n",
    "\n",
    "plt.figure(figsize=(24,9))\n",
    "plt.suptitle(f'Test sample Image {img_id}', fontsize=18)\n",
    "\n",
    "plt.subplot(1,4,1)\n",
    "plt.title('Input Image', fontsize=15)\n",
    "plt.imshow(img,cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,4,2)\n",
    "plt.title('Ground Truth', fontsize=15)\n",
    "plt.imshow(msk, cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,4,3)\n",
    "plt.title('Non-trained Network Prediction Output \\n(probability [0, 1])', fontsize=15)\n",
    "plt.imshow(pred_msk, cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,4,4)\n",
    "plt.title('Non-trained Thresholdded Binary Prediction (threshold > 0.5)', fontsize=15)\n",
    "plt.imshow(pred_msk_binary, cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bab3674-6722-43b4-ba57-399b805c1bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dice(model, loader, threshold=0.3):\n",
    "    valloss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "\n",
    "        for i_step, batch in enumerate(loader):\n",
    "            \n",
    "            data = batch['image'].cuda()\n",
    "            target = batch['mask'].cuda()\n",
    "            \n",
    "            outputs = model(data)\n",
    "\n",
    "            out_cut = np.copy(outputs.data.cpu().numpy())\n",
    "            out_cut[np.nonzero(out_cut < threshold)] = 0.0\n",
    "            out_cut[np.nonzero(out_cut >= threshold)] = 1.0\n",
    "            picloss = dice_coeff_binary(out_cut, target.data.cpu().numpy())\n",
    "            valloss += picloss\n",
    "\n",
    "    return valloss / i_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d152c57e-b1a9-4572-84da-22b8e6a9df75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_name, model, train_loader, val_loader, train_loss, optimizer, lr_scheduler, num_epochs):    \n",
    "    loss_history = []\n",
    "    train_history = []\n",
    "    val_history = []\n",
    "    val_loss_history = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        \n",
    "        losses = []\n",
    "        train_iou = []\n",
    "        \n",
    "        for i_step, batch in enumerate(tqdm(train_loader)):\n",
    "            \n",
    "            data = batch['image'].cuda()\n",
    "            target = batch['mask'].cuda()\n",
    "            \n",
    "            outputs = model(data)\n",
    "            \n",
    "            out_cut = np.copy(outputs.data.cpu().numpy())\n",
    "            out_cut[np.nonzero(out_cut < 0.5)] = 0.0\n",
    "            out_cut[np.nonzero(out_cut >= 0.5)] = 1.0\n",
    "            \n",
    "            train_dice = dice_coeff_binary(out_cut, target.data.cpu().numpy())\n",
    "            \n",
    "            loss = train_loss(outputs, target)\n",
    "            \n",
    "            losses.append(loss.item())\n",
    "            train_iou.append(train_dice)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        val_mean_iou = compute_dice(model, val_loader)\n",
    "        val_loss = train_loss(outputs, target)\n",
    "        loss_history.append(np.array(losses).mean())\n",
    "        train_history.append(np.array(train_iou).mean())\n",
    "        val_history.append(val_mean_iou)\n",
    "        val_loss_history.append(val_loss.item())\n",
    "        \n",
    "        print(\"Epoch [%d]\" % (epoch+1))\n",
    "        print(\"Training loss :\", np.array(losses).mean(), \n",
    "              \"DICE score training:\", np.array(train_iou).mean(), \n",
    "              \"DICE score validation\", val_mean_iou,\n",
    "              \"Validation loss:\", np.array(val_loss_history).mean())\n",
    "        \n",
    "    return loss_history, train_history, val_history, val_loss_history\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098065ea-7ecb-46db-9127-3bc769b16815",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.Adamax(attention_unet_myocard.parameters(), lr=1e-3) # use Adam optimizer \n",
    "loss_function = nn.BCELoss() # use BCE loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1bc133-3b89-43c8-9fe6-a0868ad9c7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "num_ep = 30\n",
    "\n",
    "aun_lh, aun_th, aun_vh, aun_vl = train_model(\"Attention UNet\", attention_unet_myocard, train_dataloader, valid_dataloader, loss_function, opt, False, num_ep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314a6ca5-b6c1-4c34-8fc6-18de8f4fb1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_model_history(\"Attention U-Net\", aun_th, aun_vh, aun_lh, aun_vl, num_ep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec3392b-aaa8-4284-9964-980ca1520ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get test DICE score \n",
    "dice_score= get_dice(attention_unet_myocard, test_dataloader)\n",
    "print(f\"\"\"Test DICE  - {dice_score}%\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbec8c6a-5170-439b-9d6c-e23abf310234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model output \n",
    "batches = []\n",
    "\n",
    "test_num = 0\n",
    "\n",
    "for batch in test_dataloader:\n",
    "    sample_batch = batch\n",
    "    batches.append(batch)\n",
    "\n",
    "sample_batch = batches[3] #0\n",
    "\n",
    "# Generat network prediction\n",
    "with torch.no_grad():\n",
    "    y_pred = attention_unet_myocard(sample_batch['image'].cuda())\n",
    "\n",
    "\n",
    "img = (sample_batch['image'][0].numpy().transpose(1,2,0) * 255).astype('uint8')\n",
    "msk = (sample_batch['mask'][0][0,:,:].numpy() * 255).astype('uint8')\n",
    "\n",
    "pred_msk = (y_pred.cpu().numpy()[0][0,:,:] * 255).astype('uint8')\n",
    "pred_msk_binary = ((y_pred.cpu().numpy()[0][0,:,:] > 0.5) * 255).astype('uint8')\n",
    "\n",
    "# Take the image id for display\n",
    "img_id = sample_batch['img_id'][0]\n",
    "\n",
    "plt.figure(figsize=(24,9))\n",
    "plt.suptitle(f'Test sample Image {img_id}', fontsize=18)\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.title('Input Image', fontsize=15)\n",
    "plt.imshow(img,cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.title('Ground Truth', fontsize=15)\n",
    "plt.imshow(msk, cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.title('Non-trained Thresholdded Binary Prediction (threshold > 0.5)', fontsize=15)\n",
    "plt.imshow(pred_msk_binary, cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccaf7bd-f3ee-41ff-9db3-c1c77b3bde59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store output masks in array\n",
    "masks_test = []\n",
    "for batch in batches: \n",
    "    with torch.no_grad():\n",
    "        y_pred = attention_unet_myocard(batch['image'].cuda())\n",
    "    for i in range(2): \n",
    "        pred_msk = ((y_pred.cpu().numpy()[0][0,:,:] > 0.5) * 255).astype('uint8')\n",
    "        masks_test.append(pred_msk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8ad91f-fcc7-49fb-9c74-3e1c5ef03a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir_attn = Path(\"C:/Users/Susanna/Documents/myocardium_segmentation/outputs/attention_u_net/epicardium/masks\")\n",
    "contours_attn = Path(\"C:/Users/Susanna/Documents/myocardium_segmentation/outputs/attention_u_net/epicardium/contours\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cc16d4-705d-4e24-9b1c-6572ee55bdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#store_outputs(masks_test, output_dir_attn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fecb96c-762b-4af7-b09d-a77ab8dcea77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#store_contours(masks_test, output_dir_attn, contours_attn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
